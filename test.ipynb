{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z4vG3e7_MZ-"
      },
      "source": [
        "#### Setup inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVUu_lgluMu4"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/LRaupp/test-diffusers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ysStCsAN_MaA"
      },
      "outputs": [],
      "source": [
        "!pip install -r \"./requirements.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuvMIBsm_MaB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "\n",
        "wkdir = \"/content/test-diffusers\"\n",
        "os.chdir(wkdir)\n",
        "\n",
        "image_ade20k = f\"{wkdir}/images/mapa_ADE20k_FIX.png\"\n",
        "image_depth = f\"{wkdir}/images/mapa_DEPTH_FIX.png\"\n",
        "image_real = f\"{wkdir}/images/mapa_REALISTIC.png\"\n",
        "image_edge = f\"{wkdir}/images/mapa_EDGE_FIX.png\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQav7fYdLyj9"
      },
      "outputs": [],
      "source": [
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTOsvMrd_MaB"
      },
      "outputs": [],
      "source": [
        "import models as M\n",
        "import torch\n",
        "from utils import preprocess_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx93eZFN_MaC"
      },
      "source": [
        "#### Prompt base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAEd9-7y_MaD"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Ultra-realistic aerial view of a modern city, captured from a high-resolution satellite or drone. Buildings, residential areas, roads, and parks are detailed and proportional, with natural lighting and depth. Clear atmosphere with soft haze near the horizon.\"\"\"\n",
        "negative_prompt = \"Distorted buildings, warped roads, AI artifacts, unnatural lighting, low detail, fisheye effect.\"\n",
        "num_images = 1\n",
        "\n",
        "prompts = [prompt]* num_images\n",
        "negative_prompts = [negative_prompt]* num_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieD5p8Ge_MaE"
      },
      "outputs": [],
      "source": [
        "tensor_size = (768, 576)\n",
        "segment_tensor = preprocess_image(image_ade20k, tensor_size)\n",
        "depth_tensor = preprocess_image(image_depth, tensor_size)\n",
        "tile_tensor = preprocess_image(image_real, tensor_size)\n",
        "canny_tensor = preprocess_image(image_edge, tensor_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BaseModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SDHFModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.SDHFModel,\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    controlnet_conditioning_scale=[0.7, 0.9, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SD1_5Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.SD1_5Model,\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    controlnet_conditioning_scale=[0.7, 0.9, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SDXL1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.SDXL1,\n",
        "    vae_model=\"madebyollin/sdxl-vae-fp16-fix\",\n",
        "    controlnet_images=(\n",
        "        (0, M.ControlModes.openpose),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (0, M.ControlModes.hed),\n",
        "        (canny_tensor, M.ControlModes.canny),\n",
        "        (0, M.ControlModes.normal),\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=5,\n",
        "    union_control=True,\n",
        "    union_control_type=torch.Tensor([0, 1, 0, 1, 0, 1]),\n",
        "    weight=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### FluxV1_Dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.FluxV1_Dev,\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    controlnet_conditioning_scale=[0.7, 0.9, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### RealisticVisionV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.RealisticVisionV2,\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    controlnet_conditioning_scale=[0.7, 0.9, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### RealisticVisionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.RealisticVisionV3,\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    controlnet_conditioning_scale=[0.7, 0.9, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### RealisticVisionV4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.RealisticVisionV4,\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    controlnet_conditioning_scale=[0.7, 0.9, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### RealisticVisionV5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.RealisticVisionV5,\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    controlnet_conditioning_scale=[0.7, 0.9, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### RealisticVisionV6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.RealisticVisionV6,\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    controlnet_conditioning_scale=[0.7, 0.9, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LoRa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LoRa (ABirdsEyeViewOfArchitectureV1) + ControlNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.SD1_5Model,\n",
        "    lora_model=M.ABirdsEyeViewOfArchitectureV1(base_local_path=\"/content/safetensors/\"),\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    controlnet_conditioning_scale=[0.7, 0.9, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LoRa (ABirdsEyeViewOfArchitectureV3) + ControlNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LoRa (AARGAerial) + ControlNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.SD1_5Model,\n",
        "    lora_model=M.AARGAerial(base_local_path=\"/content/safetensors/\"),\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=5,\n",
        "    controlnet_conditioning_scale=[1.0, 0.9, 1.0],\n",
        "    weight=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LoRa (AerialViewV2) + ControlNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.SD1_5Model,\n",
        "    lora_model=M.AerialViewV2(base_local_path=\"/content/safetensors/\"),\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=5,\n",
        "    controlnet_conditioning_scale=[1.0, 0.9, 1.0],\n",
        "    weight=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LoRa (FluxDStyleUrbanJungles) + ControlNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.FluxV1_Dev,\n",
        "    lora_model=M.FluxDStyleUrbanJungles(base_local_path=\"/content/safetensors/\"),\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=6,\n",
        "    controlnet_conditioning_scale=[1.0, 0.9, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LoRa (JZCGXL026) + ControlNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    lora_model=M.JZCGXL026(base_local_path=\"/content/safetensors/\"),\n",
        "    vae_model=\"madebyollin/sdxl-vae-fp16-fix\",\n",
        "    controlnet_images=(\n",
        "        (0, M.ControlModes.openpose),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (0, M.ControlModes.hed),\n",
        "        (canny_tensor, M.ControlModes.canny),\n",
        "        (0, M.ControlModes.normal),\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=5,\n",
        "    union_control=True,\n",
        "    union_control_type=torch.Tensor([0, 1, 0, 1, 0, 1]),\n",
        "    weight=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LoRa (JZCG005RealisticCityPhotography) + ControlNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.SD1_5Model,\n",
        "    lora_model=M.JZCG005RealisticCityPhotography(base_local_path=\"/content/safetensors/\"),\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=5,\n",
        "    controlnet_conditioning_scale=[1.0, 0.9, 1.0],\n",
        "    weight=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LoRa (UrbanRealisticCityBirdsEyeView) + ControlNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.SD1_5Model,\n",
        "    lora_model=M.UrbanRealisticCityBirdsEyeView(base_local_path=\"/content/safetensors/\"),\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=5,\n",
        "    controlnet_conditioning_scale=[1.0, 0.9, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LoRa (BirdsEyeViewUrbanDesignScenes) + ControlNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diffuser = M.PlaceDiffusionModel(\n",
        "    base_diffusion_model=M.SD1_5Model,\n",
        "    lora_model=M.BirdsEyeViewUrbanDesignScenes(base_local_path=\"/content/safetensors/\"),\n",
        "    controlnet_images=(\n",
        "        (segment_tensor, M.ControlModes.segment),\n",
        "        (depth_tensor, M.ControlModes.depth),\n",
        "        (canny_tensor, M.ControlModes.canny)\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = diffuser.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = pipe(\n",
        "    prompt=prompts,\n",
        "    negative_prompt=negative_prompts,\n",
        "    image=diffuser.control_ref_images,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=6,\n",
        "    controlnet_conditioning_scale=[0.7, 0.9, 1.0],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output.images[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
