{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10757159,
          "sourceType": "datasetVersion",
          "datasetId": 6672259
        },
        {
          "sourceId": 10757601,
          "sourceType": "datasetVersion",
          "datasetId": 6672597
        }
      ],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Lv-9FPGChcgh",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r \"/content/requirements.txt\"\n",
        "!pip install --upgrade \"torch<2.6.0\" \"xformers==0.0.28.post3\" diffusers"
      ],
      "metadata": {
        "id": "4DahWshjir5t",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T18:30:57.118223Z",
          "iopub.execute_input": "2025-02-17T18:30:57.118565Z",
          "iopub.status.idle": "2025-02-17T18:31:11.078332Z",
          "shell.execute_reply.started": "2025-02-17T18:30:57.118527Z",
          "shell.execute_reply": "2025-02-17T18:31:11.077474Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from torchvision import transforms\n",
        "from huggingface_hub import login\n",
        "\n",
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, UniPCMultistepScheduler\n",
        "from PIL import Image\n",
        "from safetensors import safe_open"
      ],
      "metadata": {
        "id": "2EhRz1C5jOlo",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T18:31:11.079637Z",
          "iopub.execute_input": "2025-02-17T18:31:11.079967Z",
          "iopub.status.idle": "2025-02-17T18:31:34.703994Z",
          "shell.execute_reply.started": "2025-02-17T18:31:11.079933Z",
          "shell.execute_reply": "2025-02-17T18:31:34.703287Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "login()"
      ],
      "metadata": {
        "id": "KvyLdHzcjWBB",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T18:31:34.705433Z",
          "iopub.execute_input": "2025-02-17T18:31:34.706148Z",
          "iopub.status.idle": "2025-02-17T18:31:34.725406Z",
          "shell.execute_reply.started": "2025-02-17T18:31:34.706105Z",
          "shell.execute_reply": "2025-02-17T18:31:34.724446Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device_name = torch.device(\"cuda\")\n",
        "    torch_dtype = torch.float16\n",
        "    print(\"Using CUDA\")\n",
        "else:\n",
        "    device_name = torch.device(\"cpu\")\n",
        "    torch_dtype = torch.float32\n",
        "    print(\"Using CPU\")"
      ],
      "metadata": {
        "id": "vRAo05STjZAP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T18:31:58.624516Z",
          "iopub.execute_input": "2025-02-17T18:31:58.624844Z",
          "iopub.status.idle": "2025-02-17T18:31:58.710223Z",
          "shell.execute_reply.started": "2025-02-17T18:31:58.624821Z",
          "shell.execute_reply": "2025-02-17T18:31:58.709184Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class LocalModel:\n",
        "    def __init__(self, local_path:str, base_model:str, controlnet_seg_model:str, controlnet_dep_model:str, controlnet_edg_model:str) -> None:\n",
        "        self.local_path = local_path\n",
        "        self.base_model = base_model\n",
        "        self.controlnet_seg_model = controlnet_seg_model\n",
        "        self.controlnet_dep_model = controlnet_dep_model\n",
        "        self.controlnet_edg_model = controlnet_edg_model"
      ],
      "metadata": {
        "id": "7Pl-XB-3jcVt",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T18:32:00.628050Z",
          "iopub.execute_input": "2025-02-17T18:32:00.628423Z",
          "iopub.status.idle": "2025-02-17T18:32:00.632984Z",
          "shell.execute_reply.started": "2025-02-17T18:32:00.628394Z",
          "shell.execute_reply": "2025-02-17T18:32:00.631980Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"./safetensors/{}\"\n",
        "base_path = \"/kaggle/input/safetensors/{}\"\n",
        "\n",
        "model_1 = LocalModel(\n",
        "  local_path=base_path.format(\"A bird's-eye view of architecture.safetensors\"),\n",
        "  base_model=\"runwayml/stable-diffusion-v1-5\",\n",
        "  controlnet_seg_model=\"lllyasviel/control_v11p_sd15_seg\",\n",
        "  controlnet_dep_model=\"lllyasviel/control_v11f1p_sd15_depth\",\n",
        "  controlnet_edg_model=\"lllyasviel/control_v11p_sd15_canny\"\n",
        ")\n",
        "model_2 = LocalModel(\n",
        "  local_path=base_path.format(\"AARG_aerial-000018.safetensors\"),\n",
        "  base_model=\"runwayml/stable-diffusion-v1-5\",\n",
        "  controlnet_seg_model=\"lllyasviel/control_v11p_sd15_seg\",\n",
        "  controlnet_dep_model=\"lllyasviel/control_v11f1p_sd15_depth\",\n",
        "  controlnet_edg_model=\"lllyasviel/control_v11p_sd15_canny\"\n",
        ")\n",
        "model_3 = LocalModel(\n",
        "  local_path=base_path.format(\"aerial view-V2.safetensors\"),\n",
        "  base_model=\"runwayml/stable-diffusion-v1-5\",\n",
        "  controlnet_seg_model=\"lllyasviel/control_v11p_sd15_seg\",\n",
        "  controlnet_dep_model=\"lllyasviel/control_v11f1p_sd15_depth\",\n",
        "  controlnet_edg_model=\"lllyasviel/control_v11p_sd15_canny\"\n",
        ")\n",
        "model_4 = LocalModel(\n",
        "  local_path=base_path.format(\"FLUXD-Style-Urban_Jungles-urjungle.safetensors\"),\n",
        "  base_model=\"black-forest-labs/FLUX.1-dev\",\n",
        "  controlnet_seg_model=\"lllyasviel/control_v11p_sd15_seg\",\n",
        "  controlnet_dep_model=\"lllyasviel/control_v11f1p_sd15_depth\",\n",
        "  controlnet_edg_model=\"lllyasviel/control_v11p_sd15_canny\"\n",
        ")"
      ],
      "metadata": {
        "id": "ChS5uh65jleD",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# https://docs.google.com/spreadsheets/d/1se8YEtb2detS7OuPE86fXGyD269pMycAWe2mtKUj2W8/edit?gid=0#gid=0\n",
        "# ADE20K Class -> Roads -> #8C8C8C\n",
        "# ADE20K Class -> Buildings -> #B47878\n",
        "# ADE20K Class -> Grass -> #04FA07\n",
        "# ADE20K Class -> Water -> #3DE6FA\n",
        "# ADE20K Class -> Sidewalk -> #EBFF07\n",
        "# ADE20K Class -> Sky -> #06E6E6\n",
        "\n",
        "\n",
        "# Local\n",
        "model = model_3\n",
        "\n",
        "controlnet_depth = ControlNetModel.from_pretrained(\n",
        "    model.controlnet_dep_model, torch_dtype=torch_dtype\n",
        ").to(device_name)\n",
        "controlnet_seg = ControlNetModel.from_pretrained(\n",
        "    model.controlnet_seg_model, torch_dtype=torch_dtype\n",
        ").to(device_name)\n",
        "controlnet_edge = ControlNetModel.from_pretrained(\n",
        "    model.controlnet_edg_model, torch_dtype=torch_dtype\n",
        ").to(device_name)\n",
        "\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    model.base_model,\n",
        "    controlnet=[controlnet_depth, controlnet_seg, controlnet_edge],\n",
        "    torch_dtype=torch_dtype\n",
        ").to(device_name)\n",
        "pipe.load_lora_weights(model.local_path)\n",
        "pipe.fuse_lora()\n",
        "\n",
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# HF\n",
        "# controlnet_depth = ControlNetModel.from_pretrained(\n",
        "#     \"lllyasviel/control_v11f1p_sd15_depth\", torch_dtype=torch_dtype\n",
        "# ).to(device_name)\n",
        "# controlnet_seg = ControlNetModel.from_pretrained(\n",
        "#     \"lllyasviel/control_v11p_sd15_seg\", torch_dtype=torch_dtype\n",
        "# ).to(device_name)\n",
        "\n",
        "# pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "#     \"runwayml/stable-diffusion-v1-5\", controlnet=[controlnet_depth, controlnet_seg], torch_dtype=torch_dtype,\n",
        "#     use_auth_token=True\n",
        "# ).to(device_name)\n",
        "\n",
        "# from diffusers import StableDiffusion3Pipeline\n",
        "\n",
        "# pipe = StableDiffusion3Pipeline.from_pretrained(\n",
        "#     \"stabilityai/stable-diffusion-3.5-large-turbo\", torch_dtype=torch_dtype\n",
        "# ).to(device_name)"
      ],
      "metadata": {
        "id": "EchTuFekjsRR",
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# File paths\n",
        "image_paths = {\n",
        "    \"real\": \"./images/mapa_REALISTIC.png\",\n",
        "    \"depth\": \"./images/mapa_DEPTH_FIX.png\",\n",
        "    \"seg\": \"./images/mapa_ADE20K_FIX.png\",\n",
        "    \"edge\": \"./images/mapa_EDGE.png\",\n",
        "}\n",
        "\n",
        "# Image processing function\n",
        "def load_image(image_path, size=(512, 512)):\n",
        "    image = Image.open(image_path).convert(\"RGB\")  # Use PIL directly (no need for OpenCV)\n",
        "    image = image.resize(size, Image.LANCZOS)  # Higher-quality resize method\n",
        "    return image\n",
        "\n",
        "# Load images\n",
        "images = {key: load_image(path) for key, path in image_paths.items()}\n",
        "\n",
        "# Convert images to tensors\n",
        "transform = transforms.ToTensor()\n",
        "image_tensors = {key: transform(img).unsqueeze(0) for key, img in images.items()}\n",
        "\n",
        "# Access individual tensors\n",
        "tile_tensor = image_tensors[\"real\"]\n",
        "depth_tensor = image_tensors[\"depth\"]\n",
        "seg_tensor = image_tensors[\"seg\"]\n",
        "edge_tensor = image_tensors[\"edge\"]"
      ],
      "metadata": {
        "id": "HW4RvkL_3wTq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T18:32:08.341843Z",
          "iopub.execute_input": "2025-02-17T18:32:08.342281Z",
          "iopub.status.idle": "2025-02-17T18:32:08.347788Z",
          "shell.execute_reply.started": "2025-02-17T18:32:08.342244Z",
          "shell.execute_reply": "2025-02-17T18:32:08.346591Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Ultra-realistic aerial view of a modern city, captured from a high-resolution satellite or drone. Skyscrapers, residential areas, roads, and parks are detailed and proportional, with natural lighting and depth. No distortions, warped buildings, or AI artifacts. Clear atmosphere with soft haze near the horizon.\"\"\"\n",
        "negative_prompt = \"Distorted buildings, warped roads, AI artifacts, unnatural lighting, low detail, fisheye effect.\"\n",
        "num_images = 1"
      ],
      "metadata": {
        "id": "Gp9Am8C6kb6O",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T18:32:12.507374Z",
          "iopub.execute_input": "2025-02-17T18:32:12.507823Z",
          "iopub.status.idle": "2025-02-17T18:32:12.513246Z",
          "shell.execute_reply.started": "2025-02-17T18:32:12.507781Z",
          "shell.execute_reply": "2025-02-17T18:32:12.512287Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONTROLNET3 + SD3"
      ],
      "metadata": {
        "id": "m1wwbg_1M2UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers.models import SD3ControlNetModel, SD3MultiControlNetModel\n",
        "from diffusers import StableDiffusion3ControlNetPipeline\n",
        "\n",
        "# load pipeline\n",
        "controlnet_canny = SD3ControlNetModel.from_pretrained(\"InstantX/SD3-Controlnet-Canny\", torch_dtype=torch_dtype)\n",
        "controlnet_depth = SD3ControlNetModel.from_pretrained(\"InstantX/SD3-Controlnet-Depth\", torch_dtype=torch_dtype)\n",
        "controlnet_tile = SD3ControlNetModel.from_pretrained(\"InstantX/SD3-Controlnet-Tile\", torch_dtype=torch_dtype)\n",
        "\n",
        "pipe = StableDiffusion3ControlNetPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-3-medium-diffusers\",\n",
        "    controlnet=[controlnet_canny, controlnet_depth, controlnet_tile],\n",
        "    torch_dtype=torch_dtype\n",
        ")\n",
        "\n",
        "# Move to CUDA first\n",
        "pipe.to(device_name)\n",
        "\n",
        "# Apply xformers optimization\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "# Compile U-Net for optimization (AFTER moving to CUDA)\n",
        "pipe.unet = torch.compile(pipe.unet)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T18:32:57.442613Z",
          "iopub.execute_input": "2025-02-17T18:32:57.442953Z",
          "execution_failed": "2025-02-17T18:35:56.334Z"
        },
        "id": "NV2_8P3DM2UD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "image = pipe(\n",
        "    prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    control_image=[edge_tensor, depth_tensor, tile_tensor],\n",
        "    controlnet_conditioning_scale=[1.0, 1.0, 1.0],\n",
        ").images[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "GSfgjeFHM2UD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "trusted": true,
        "id": "HiXQYc73M2UE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONTROLNET"
      ],
      "metadata": {
        "id": "t3UHkPI86J_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=[depth_tensor, seg_tensor, edge_tensor],\n",
        "    num_inference_steps=25,\n",
        "    strength=0.00001,\n",
        "    guidance_scale=0.00001,\n",
        "    controlnet_conditioning_scale=[1.0, 1.0, 1.0],\n",
        ")"
      ],
      "metadata": {
        "id": "i-CGqgiJkj5u",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output.images[0]"
      ],
      "metadata": {
        "id": "ocMYrouXkpQD",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMG 2 IMG"
      ],
      "metadata": {
        "id": "qiF4kBYz6He9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch_dtype\n",
        ").to(\"cuda\")"
      ],
      "metadata": {
        "id": "PUi3OI1p5sbn",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=base_image,\n",
        "    strength=0.2,  # Controls how much the image should change (0 = minor edits, 1 = full generation)\n",
        "    guidance_scale=1,  # Higher values enforce the prompt more\n",
        "    num_inference_steps=50,\n",
        ")"
      ],
      "metadata": {
        "id": "lssPIFYE59Pf",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "output.images[0]"
      ],
      "metadata": {
        "id": "NLuq3L616OIT",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yqeIGydj6Zvz",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TESTE SHAKKER"
      ],
      "metadata": {
        "id": "DbRW0BkyM2UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, DPMSolverMultistepScheduler\n",
        "from diffusers.models import AutoencoderKL\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load Base Model (Stable Diffusion 1.5 or Realistic Vision V2.0)\n",
        "base_model = \"SG161222/Realistic_Vision_V2.0\"\n",
        "\n",
        "# Load ControlNet Models for Depth, Edge, and ADE20K Segmentation\n",
        "controlnet_depth = ControlNetModel.from_pretrained(\"lllyasviel/control_v11f1p_sd15_depth\", torch_dtype=torch.float16)\n",
        "controlnet_edge = ControlNetModel.from_pretrained(\"lllyasviel/control_v11p_sd15_canny\", torch_dtype=torch.float16)\n",
        "controlnet_seg = ControlNetModel.from_pretrained(\"lllyasviel/control_v11p_sd15_seg\", torch_dtype=torch.float16)  # ADE20K\n",
        "\n",
        "# Combine ControlNets\n",
        "controlnets = [controlnet_depth, controlnet_edge, controlnet_seg]\n",
        "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\", torch_dtype=torch.float16)\n",
        "\n",
        "# Load Pipeline with ControlNets\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    base_model,\n",
        "    controlnet=controlnets,\n",
        "    vae=vae,\n",
        "    torch_dtype=torch.float16\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Use DPM++ 2M Karras Sampler for better results\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# Load Depth, Edge, and ADE20K Segmentation Maps\n",
        "depth_map = Image.open(\"/kaggle/input/teste-diffusers/images/mapa_DEPTH_FIX.png\").convert(\"RGB\").resize((768, 576))\n",
        "edge_map = Image.open(\"/kaggle/input/teste-diffusers/images/mapa_EDGE.png\").convert(\"RGB\").resize((768, 576))\n",
        "ade20k_map = Image.open(\"/kaggle/input/teste-diffusers/images/mapa_ADE20K_FIX.png\").convert(\"RGB\").resize((768, 576))  # ADE20K\n",
        "\n",
        "# Convert images to numpy arrays (normalized)\n",
        "depth_array = np.array(depth_map) / 255.0\n",
        "edge_array = np.array(edge_map) / 255.0\n",
        "ade20k_array = np.array(ade20k_map) / 255.0"
      ],
      "metadata": {
        "trusted": true,
        "id": "JdzkiGSoM2UG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Image\n",
        "prompt = \"\"\"Ultra-realistic aerial view of a modern city, captured from a high-resolution satellite or drone. Skyscrapers, residential areas, roads, and parks are detailed and proportional, with natural lighting and depth. No distortions, warped buildings, or AI artifacts. Clear atmosphere with soft haze near the horizon.\"\"\"\n",
        "negative_prompt = \"Distorted buildings, warped roads, AI artifacts, unnatural lighting, low detail, fisheye effect.\"\n",
        "\n",
        "# Run Stable Diffusion with ControlNets\n",
        "output = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=[depth_map, edge_map, ade20k_map],\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    controlnet_conditioning_scale=[1.0, 0.9, 0.8],\n",
        ")\n",
        "\n",
        "# Save output\n",
        "output.images[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "dYDJHSsjM2UH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "8DMRoaxRM2UH"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}